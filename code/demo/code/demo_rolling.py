import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import torch

from persistent_multiscale_incremental import MultiScaleModelManager, ManagerConfig  # âš ï¸ æ”¹æˆä½ è‡ªå·±çš„æ¨¡å—è·¯å¾„
# from persistent_multiscale import MultiScaleModelManager

# === ä¸´æ—¶è°ƒè¯•ï¼šå¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç†æ—§ checkpoint ç›®å½• ===
import shutil
import os
for f in os.listdir('.'):
    if f.startswith("checkpoints_") and os.path.isdir(f):
        try:
            shutil.rmtree(f)
            print(f"[debug] deleted old checkpoint directory: {f}")
        except Exception as e:
            print(f"[debug] failed to delete {f}: {e}")
# === ç»“æŸ ===


# =====================================================
# âœ… ç”¨æˆ·é…ç½®åŒºï¼ˆç›´æ¥æ”¹è¿™é‡Œå³å¯ï¼‰
# =====================================================
DATA_PATH = "data.parquet"
LOOKUP_PATH = "taxi-zone-lookup.csv"
CHECKPOINT_DIR = "checkpoints_multiscale"

START_TARGET = pd.Timestamp("2021-03-06 12:00")  # ç¬¬721å°æ—¶
ROLLING_STEPS = 3                               # è¿ç»­é¢„æµ‹24å°æ—¶
HIDDEN_SIZE = 64                                 # æ¨¡å‹éšè—å±‚å¤§å°
# EXCLUDED_ZONES = [1,2,3,   103, 104, 105, 46, 264, 265]   # æ’é™¤çš„åŒºåŸŸ
EXCLUDED_ZONES = [103, 104, 105, 46, 264, 265]   # æ’é™¤çš„åŒºåŸŸ
RETRAIN_EACH_HOUR = False                        # æ˜¯å¦æ¯å°æ—¶é‡æ–°è®­ç»ƒ
# =====================================================


def prepare_df():
    df = pd.read_parquet(DATA_PATH, columns=["pickup_datetime", "PULocationID"])
    df["pickup_datetime"] = pd.to_datetime(df["pickup_datetime"])
    df["datetime"] = df["pickup_datetime"].dt.floor("h")
    df = df[~df["PULocationID"].isin(EXCLUDED_ZONES)]
    # df = df[df["PULocationID"].isin(EXCLUDED_ZONES)]

    return df


def get_true_counts(df, target_hour):
    mask = df["datetime"] == target_hour
    return df.loc[mask].groupby("PULocationID").size()


def run_rolling(df, manager):
    seq_len = 24 * 30
    zones = sorted(df["PULocationID"].unique())
    records, metrics = [], []

    for step in range(ROLLING_STEPS):
        target_ts = START_TARGET + pd.Timedelta(hours=step)
        print(f"\n/////Predicting target hour: {target_ts} in step {step}/////")

        # æ¯å°æ—¶é‡è®­ï¼šåˆ›å»ºç‹¬ç«‹checkpointç›®å½•
        if RETRAIN_EACH_HOUR:
            hour_dir = Path(CHECKPOINT_DIR) / target_ts.strftime("%Y%m%d_%H%M")
            hour_dir.mkdir(parents=True, exist_ok=True)
            mgr = MultiScaleModelManager(checkpoint_dir=str(hour_dir), hidden_size=HIDDEN_SIZE)
        else:
            mgr = manager

        y_true_dict = get_true_counts(df, target_ts)
        preds, trues = [], []

        for zid in zones:
            try:
                print(f"-----current zone is {zid}-----")
                pred = mgr.train_and_predict_if_needed(df, zid, target_ts, auto_train=True)
                true_val = float(y_true_dict.get(zid, 0))
                records.append({"target_hour": target_ts, "PULocationID": zid, "y_pred": pred, "y_true": true_val})
                preds.append(pred)
                trues.append(true_val)
            except Exception as e:
                records.append({"target_hour": target_ts, "PULocationID": zid, "y_pred": np.nan, "y_true": np.nan, "error": str(e)})

        if preds:
            preds, trues = np.array(preds), np.array(trues)
            mask = ~np.isnan(preds) & ~np.isnan(trues)
            mean_true = np.mean(trues[mask])
            if mask.any():
                mae = np.mean(np.abs(preds[mask] - trues[mask]))
                rmse = np.sqrt(np.mean((preds[mask] - trues[mask]) ** 2))

                metrics.append({
                    "target_hour": target_ts,
                    "MAE": mae,
                    "RMSE": rmse,
                    "NMAE": mae / (mean_true + 1e-8),
                    "NRMSE": rmse / (mean_true + 1e-8),
                    "mean_true": mean_true
                })
                print(f"âœ… MAE={mae:.3f}, RMSE={rmse:.3f}ï¼ŒNMAE={mae / (mean_true + 1e-8)}ï¼ŒNMSE={rmse / (mean_true + 1e-8)}")
            else:
                metrics.append({"target_hour": target_ts, "MAE": np.nan, "RMSE": np.nan})
        else:
            metrics.append({"target_hour": target_ts, "MAE": np.nan, "RMSE": np.nan})

    # ä¿å­˜ç»“æœ


    pred_df = pd.DataFrame(records)
    if Path(LOOKUP_PATH).exists():
        lookup = pd.read_csv(LOOKUP_PATH)
        pred_df = pred_df.merge(lookup[["LocationID", "Zone"]],
                                left_on="PULocationID", right_on="LocationID", how="left").drop(columns=["LocationID"])
    pred_df.to_csv("predictions_rolling.csv", index=False)

    metrics_df = pd.DataFrame(metrics)
    metrics_df.to_csv("hourly_metrics.csv", index=False)

    all_data = pred_df.dropna(subset=["y_pred", "y_true"])
    if not all_data.empty:
        overall_mae = np.mean(np.abs(all_data["y_pred"] - all_data["y_true"]))
        overall_rmse = np.sqrt(np.mean((all_data["y_pred"] - all_data["y_true"]) ** 2))
    else:
        overall_mae = overall_rmse = np.nan

    with open("overall_metrics.txt", "w", encoding="utf-8") as f:
        f.write(f"Overall MAE: {overall_mae}\nOverall RMSE: {overall_rmse}\n")

    print(f"\nğŸ¯ Overall MAE={overall_mae:.4f}, RMSE={overall_rmse:.4f}")


def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("CUDA available:", torch.cuda.is_available())
    print("Using device:", device)
    df = prepare_df()

    cfg = ManagerConfig(hidden_size=HIDDEN_SIZE)
    manager = MultiScaleModelManager(checkpoint_dir=CHECKPOINT_DIR, cfg=cfg)
    # manager = MultiScaleModelManager(checkpoint_dir=CHECKPOINT_DIR, hidden_size=HIDDEN_SIZE)

    run_rolling(df, manager)



if __name__ == "__main__":
    main()
